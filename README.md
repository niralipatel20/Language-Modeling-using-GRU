# Language-Modeling-using-GRU
This repository presents the implementation of a character-level language model utilizing a Gated Recurrent Unit (GRU) neural network in TensorFlow/Keras. The model is trained on a text dataset to predict subsequent characters, facilitating text generation. 
